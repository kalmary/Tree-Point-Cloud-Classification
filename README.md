![BANNER](https://github.com/kalmary/RandLANet_Segmentation/blob/readme-preparation/img/Banner.png)


**RandLANet_Segmentation** is ...

---

### Table of contents
1. [Instalation](#instalation)
2. [Folder Structure](#fstructure)
3. [Usage](#usage)
4. [Main piplines after training](#piplines)


---

### 1. Instalation:

```bash

# Clone the repository to your local machine:

git clone https://github.com/kalmary/RandLANet_Segmentation.git

cd RandLANet_Segmentation

# Create and activate a Virtual Environment:
python -m venv .venv
source .venv/bin/activate

# Install all requirements, without pytorch and cuda
pip install requirements.txt

# Tested on this, but should work with any other version
pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/cu128

# update git submodules
git submodule update --init --recursive
```

---

### 2. Folder structure:

```
.
├── data_processing
│   └── downsample_LAZ.py        #Program for preprocessing point cloud files. Creates hdf5 files for training, validation and testing
├── final_files                  #Folder prepared for trained models and their config files
├── main_logs                    
├── main.py                      
├── model_pipeline
│   ├── TrainSegmAutomated.py    #Main Python Program for training 
│   ├── EvalSegm_RandLANet.py    #Main Python Program for evaluating outputs
│   ├── RandLANet_CB.py          #RandLANet model, configurable from dictionary
│   ├── model_configs            #Folder containing all architecture config files
│   ├── training_configs         #Folder containign all parameters config files
│   ├── training_results         #Folder containing all files generated by training and evalutaion files

└── utils
    ├── nn_utils                 #nn_utils (external link)     
    └── pcd_manipulation.py      #Point clound manipulations

```

### 3. Usage

---

For training purposes:


```bash
cd src/model_pipeline
python TrainSegmAutomated.py --help
```

Output of --help


```
Script for training the model based on predefined range of scenarios

options:
  -h, --help            show this help message and exit
  --model_name MODEL_NAME
                        Base of the model's name.
                        When iterating, name also gets an ID. 
                        If not given, defaults to: ResNet_0.
  --device {cpu,cuda,gpu}
                        Device for tensor based computation.
                        Pick 'cpu' or 'cuda'/ 'gpu'.
                        Device for tensor based computation.
  --mode {0,1,2,3,4}    
                        Pick:
                        0: test
                        1: single training
                        2: multiple trainings, grid_based
                        3: multiple trainings, with optuna
                        4: only check models
```

Training mode:

* **Test** - This mode uses a dummy model to check if the overall system and configuration are working correctly.
* **Single training** - Performs a single training run using a specified model and defined configuration settings.
* **Multiple training grid_based** - Executes multiple training runs for hyperparameter tuning by systematically testing all combinations defined in a grid search configuration.
* **Multiple training optuna** - Performs advanced hyperparameter optimization using Optuna. This mode can efficiently find a better optimal solution, often taking more time than a simple grid search. You can also utilize the Optuna Dashboard for visualization and monitoring.
* **Only check models** - This mode check if model compiles.

---

For evaluating:


```bash
cd src/model_pipeline
python EvalSegm_RandLANet.py --help
```
Output of --help

```bash

```


---

### 4. Main piplines after training


| Pipline for processing point clouds in arrays | Pipline for processing laz files |
| :---: | :---: |
| Using main.py.... | Opis 2 |




