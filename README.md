![BANNER](https://github.com/kalmary/RandLANet_Segmentation/blob/readme-preparation/img/Banner.png)

# Table of contents
1. [Overview](#overview)
2. [Repository Structure](#fstructure)
3. [Installation](#installation)
4. [Usage](#usage)
    1. [Preprocessing](#preprocessing)
    2. [Training](#training)
    3. [Evaluation](#evaluation)
6. [Final data processing](#piplines)
7. [Citation](#citation)

--- 
# 1. Overview <a name="overview"></a>

**RandLANet_Segmentation** is a set of tools for point cloud semantic segmentation using the RandLANet architecture. RandLANet is a deep learning model designed to process large-scale point clouds. Its architecture, which utilizes a random sampling strateg. The repository includes tools for defining the model, training it, and performing segmentation on new files. Key Features:
- Data preprocessing: cut, decimate and distribite data for training model,
- Model definition: necessary code to define and build the RandLANet model architecture, allows for scalability and adjustment for hardware-specific needs,
- Training & Evaluation: Tools for training the model on custom datasets and evaluating its performance,
- Inference & Segmentation: Utility to perform semantic segmentation on new point cloud files using pre-trained models/ segmentation on preloaded arrays.



Our model is based on:
- https://github.com/QingyongHu/RandLA-Net
- https://github.com/aRI0U/RandLA-Net-pytorch


![IMG](https://github.com/kalmary/RandLANet_Segmentation/blob/readme-preparation/img/RandLANet_scheme.png)


Key modifications we added:
- like memory efficient, gpu - based knn search,
- model configurability from .json file,
- better decoder upsampling.

---
# 2. Repository structure: <a name="fstructure"></a>

```
.
├── data_processing
│   └── downsample_LAZ.py        #Program for preprocessing point cloud files. Creates hdf5 files for training, validation and testing
├── final_files                  #Folder prepared for trained models and their config files
├── main_logs                    
├── main.py                      
├── model_pipeline
│   ├── TrainSegmAutomated.py    #Main Python Program for training 
│   ├── EvalSegm_RandLANet.py    #Main Python Program for evaluating outputs
│   ├── RandLANet_CB.py          #RandLANet model, configurable from dictionary
│   ├── model_configs            #Folder containing all architecture config files
│   ├── training_configs         #Folder containign all parameters config files
│   ├── training_results         #Folder containing all files generated by training and evalutaion files
└── utils
    ├── nn_utils                 #nn_utils (external link)     
    └── pcd_manipulation.py      #Point clound manipulations

```
---

# 3. Instalation: <a name="installation"></a>

Clone the repository to your local machine:
```bash

git clone https://github.com/kalmary/RandLANet_Segmentation.git

cd RandLANet_Segmentation
```

Create and activate a Virtual Environment and install requirements:
```bash
python -m venv .venv
source .venv/bin/activate

# Install all requirements, without pytorch and cuda
pip install requirements.txt

# Tested on this, but should work with any other version
pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/cu128

# update git submodules
git submodule update --init --recursive
```

---

# 4. Usage <a name="usage"></a>
## 1. Preprocessing <a name="preprocessing"></a>

Before training a model, data preprocessing must be done. To do so run:
```bash
python src/data_processing/downsample_LAZ.py --source_path path/to/raw/data --decimated_path path/to/decimated/pcds --converted_path path/to/final/processed/files
```
Paths used when processing:
- source_path: directory with raw (.LAZ by default) point clouds,
- decimated_path: serves as a checkpoint. Files are cut, decimated and saved as .npy files,
- converted_path: final directory with processed files, distributed into training/ validation/ testing datasets, chunked into .h5 files,

For more guidance/ guidance when running code, run it with ``--help`` flag.

## 2. Training <a name="training"></a>
Examine contents of:
- ``src/model_pipeline/model_configs`` - .json files with model architectures,
- ``src/model_pipeline/training_configs`` - .json files with training configs.
Pay attention to above files and adjust them to ensure the fit with your available resources.
  
Files with `_single` suffix are meant for single training without any optimizations. Others are for multi-hyperparameter optimization.

To start training run:
```bash
cd src/model_pipeline
python src/model_pipeline/TrainSegmAutomated.py --model_name MODEL_NAME --device cuda --mode 3
```
Available flags:
- ``model_name`` - name of your model. Results are stored in ``src/model_pipeline/training_results/MODEL_NAME``,
- ``device`` - we recommend training on strong GPUs (tested on RTX 5090), but any CUDA enabled one with at least 16 GB of VRAM (smaller models), will work fine,
- ``mode`` - you can choose following:
    - `0` - testing mode: ,
    - `1` - single training without optimizations: good choice if fast/ based on known optimal parameters training is required.,
    - `2` - grid based optimal hyperparameters search: only with optimization case is really simple/ configs combination number is low,,
    - `3` - Optuna library based hyperparameter search: for high dimensional and complex cases. If you have special needs in terms of time computation,
    - `4` - check models - run this to get a rough idea of model resource demands.
 

For most optimal results we recommend using options based on multidimensional space of hyperparameters. If you choose Optuna based option you can change ``n_trials`` in ``main`` function of ``TrainSegmAutomated.py``:
```python
optuna_based_training(exp_config=exp_configs,
                      model_name=model_name,
                      n_trials=80)

```
``n_trials=80`` is what we found to be giving good, repeatable results, but lower numbers where also acceptable. Even if the optimization process takes too long, 
best model and its config are saved and overwritten if a better model is found. Alongside them, plots with metrics history (loss, accuracy, mIoU) are also saved.

For more guidance/ guidance when running code, run it with ``--help`` flag.

## 3. Evaluation <a name="evaluation"></a>

To evaluate trained model, run EvalSegm_RandLANet.py with proper flags:

```bash
cd src/model_pipeline
python src/model_pipeline/EvalSegm_RandLANet.py --model_name MODEL_NAME --device cuda --mode 1
```
``model_name`` flag must be the exact name of model you got from training, but without extension name. For example:
```
RandLANetTest_123.pt -> RandLANetTest_123
```
Available modes are:
- 0: testing mode:  check if model compiles and works as expected
- 1: evaluation mode
  
Evaluation mode output are plots:
- Precision recall curve,
- Receiver operating characteristic curve,
- Confusion matrix
Last output is text classification report generated by ``classification_report`` from ``scikit-learn``.

As previously, you can run it with ``--help`` flag.


# 5. Final data processing <a name="pipelines"></a>


# 6. Citation <a name="citation"></a>















